# Text DataModule Configuration
# Contains: tokenization, sequence handling, data loading

_target_: src.data.text_datamodule.TextDataModule

# Dataset Identity
dataset_name: "imdb"            # imdb / sst2 / custom
data_dir: ${paths.data_dir}

# Tokenization (critical: lives with data, not model)
tokenizer_name: "bert-base-uncased"
max_seq_len: 512
padding: true
truncation: true
add_special_tokens: true

# Data Split
train_split: "train"
val_split: 0.1
test_split: "test"

# Batch & Loader
batch_size: 32
num_workers: 4
pin_memory: true
persistent_workers: true

# Collation
dynamic_padding: true           # pad to longest in batch vs fixed length
